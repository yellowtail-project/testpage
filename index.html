<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>iPad Safari - 3秒録画 + MediaPipe Blendshapes</title>
  <style>
    body { font-family: system-ui, -apple-system, sans-serif; margin: 16px; }
    .row { display: flex; gap: 12px; flex-wrap: wrap; align-items: center; }
    button { padding: 10px 14px; font-size: 16px; }
    video { width: 320px; max-width: 100%; background: #000; border-radius: 8px; }
    canvas { width: 320px; max-width: 100%; border: 1px solid #ddd; border-radius: 8px; }
    pre { white-space: pre-wrap; background: #f6f6f6; padding: 12px; border-radius: 8px; max-width: 680px; }
    .hint { color: #555; font-size: 13px; }
  </style>
</head>
<body>
  <h2>3秒録画 → 各フレームでFace Blendshapes表示（MediaPipe）</h2>

  <div class="row">
    <button id="btnCam">カメラ起動（インカメ）</button>
    <button id="btnRec" disabled>撮影開始（3秒）</button>
  </div>
  <p class="hint">
    ※HTTPSで配信してください（例：ローカルなら簡易サーバー）。ボタン操作後にカメラ許可が出ます。
  </p>

  <div class="row" style="margin-top: 12px;">
    <div>
      <div class="hint">プレビュー（カメラ）</div>
      <video id="preview" playsinline autoplay muted></video>
    </div>

    <div>
      <div class="hint">解析用（録画Blob再生）</div>
      <video id="playback" playsinline controls></video>
    </div>

    <div>
      <div class="hint">解析フレーム（canvas）</div>
      <canvas id="canvas" width="320" height="240"></canvas>
    </div>
  </div>

  <h3>Blendshapes（各フレーム）</h3>
  <pre id="out">未解析</pre>

  <script type="module">
    import { FilesetResolver, FaceLandmarker } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.21";

    const btnCam = document.getElementById("btnCam");
    const btnRec = document.getElementById("btnRec");
    const preview = document.getElementById("preview");
    const playback = document.getElementById("playback");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const out = document.getElementById("out");

    let stream = null;
    let recorder = null;
    let chunks = [];
    let faceLandmarker = null;

    // MediaPipe FaceLandmarker 初期化
    async function initMediapipe() {
      if (faceLandmarker) return faceLandmarker;

      const fileset = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.21/wasm"
      );

      // model: face_landmarker.task をCDNから取得
      faceLandmarker = await FaceLandmarker.createFromOptions(fileset, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          delegate: "GPU" // iOS SafariでGPUが使えない場合は自動的にCPU相当に落ちることもあります
        },
        runningMode: "VIDEO",
        outputFaceBlendshapes: true,
        numFaces: 1
      });

      return faceLandmarker;
    }

    // インカメ起動
    btnCam.addEventListener("click", async () => {
      out.textContent = "カメラ起動中...";
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: "user",
            width: { ideal: 1280 },
            height: { ideal: 720 }
          },
          audio: false
        });
        preview.srcObject = stream;

        await initMediapipe();

        btnRec.disabled = false;
        out.textContent = "カメラ起動OK。次に「撮影開始（3秒）」を押してください。";
      } catch (e) {
        console.error(e);
        out.textContent = "カメラ起動に失敗: " + e.message;
      }
    });

    // 3秒録画
    btnRec.addEventListener("click", async () => {
      if (!stream) return;

      out.textContent = "録画開始...";
      chunks = [];

      // iOS SafariでmimeTypeが通らない場合があるので、まずは指定なしで作る（最も互換が高い）
      try {
        recorder = new MediaRecorder(stream);
      } catch (e) {
        out.textContent = "MediaRecorderが使えない/初期化できない: " + e.message;
        return;
      }

      recorder.ondataavailable = (ev) => {
        if (ev.data && ev.data.size > 0) chunks.push(ev.data);
      };

      recorder.onstop = async () => {
        const blob = new Blob(chunks, { type: recorder.mimeType || "video/webm" });
        out.textContent = `録画完了。Blobサイズ: ${blob.size.toLocaleString()} bytes\n解析準備中...`;

        // 録画Blobを再生用videoへ
        const url = URL.createObjectURL(blob);
        playback.src = url;
        playback.currentTime = 0;

        // メタデータ読み込み待ち
        await new Promise((res) => {
          if (playback.readyState >= 1) return res();
          playback.onloadedmetadata = () => res();
        });

        // 解析開始（フレームごと）
        await analyzeVideoFrames();
        out.textContent += "\n\n解析完了。";
      };

      recorder.start();

      // 3秒で停止
      setTimeout(() => {
        if (recorder && recorder.state !== "inactive") recorder.stop();
      }, 3000);
    });

    // フレームごとにblendshapes推論して表示
    async function analyzeVideoFrames() {
      const landmarker = await initMediapipe();

      // 再生開始
      await playback.play();

      // iOS Safari: requestVideoFrameCallback が使えればそれを優先
      if ("requestVideoFrameCallback" in HTMLVideoElement.prototype) {
        await new Promise((resolve) => {
          const step = async (now, metadata) => {
            if (playback.ended || playback.paused) {
              resolve();
              return;
            }
            await processOneFrame(landmarker, metadata.mediaTime * 1000);
            playback.requestVideoFrameCallback(step);
          };
          playback.requestVideoFrameCallback(step);
        });
      } else {
        // フォールバック: タイマーで疑似的にフレーム処理（精度は落ちます）
        await new Promise((resolve) => {
          const timer = setInterval(async () => {
            if (playback.ended || playback.paused) {
              clearInterval(timer);
              resolve();
              return;
            }
            // videoの現在時刻(ms)
            await processOneFrame(landmarker, playback.currentTime * 1000);
          }, 1000 / 30);
        });
      }
    }

    async function processOneFrame(landmarker, timestampMs) {
      // video → canvas
      // サイズ調整（縦横比をざっくり合わせる）
      const vw = playback.videoWidth || 320;
      const vh = playback.videoHeight || 240;
      canvas.width = 320;
      canvas.height = Math.round(320 * (vh / vw));

      ctx.drawImage(playback, 0, 0, canvas.width, canvas.height);

      // 推論（VIDEOモード）
      const result = landmarker.detectForVideo(playback, timestampMs);

      // 表示（上位だけ）
      const face = result.faceBlendshapes?.[0];
      if (!face) {
        out.textContent = `t=${(timestampMs/1000).toFixed(3)}s\n顔検出なし`;
        return;
      }

      // categories: {categoryName, score} の配列
      const top = [...face.categories]
        .sort((a, b) => b.score - a.score)
        .slice(0, 12);

      out.textContent =
        `t=${(timestampMs/1000).toFixed(3)}s\n` +
        top.map(c => `${c.categoryName}: ${c.score.toFixed(3)}`).join("\n");
    }
  </script>
</body>
</html>
